{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "from queue import PriorityQueue\n",
    "import cv2\n",
    "import gym\n",
    "from gym import spaces\n",
    "from math import sqrt\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(grid, agent_point=(0,0), end_point=(0,0), inline=False):\n",
    "    game_visual = np.zeros((grid.shape[0], grid.shape[0], 3), np.uint8)\n",
    "#     game_visual.fill(255)\n",
    "    wall_pos = np.where(grid==1)\n",
    "    for index, _ in enumerate(wall_pos[0]):\n",
    "        game_visual[wall_pos[0][index], wall_pos[1][index]] = (3, 78, 252) \n",
    "    \n",
    "    if not inline:\n",
    "        if agent_point == end_point:\n",
    "            game_visual[end_point[0], end_point[1]] = (0, 255, 0) \n",
    "\n",
    "        else:\n",
    "            game_visual[agent_point[0], agent_point[1]] = (255, 255, 255) \n",
    "            game_visual[end_point[0], end_point[1]] = (247, 235, 10) \n",
    "            \n",
    "        game_visual = cv2.cvtColor(game_visual, cv2.COLOR_RGB2BGR)\n",
    "        cv2.namedWindow(\"Pacman Simplified\", cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(\"Pacman Simplified\", 500, 500)\n",
    "        cv2.imshow('Pacman Simplified', game_visual)\n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    return game_visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Generation (Cellular Automata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapGenerationCA():\n",
    "    def __init__(self, grid_size=(30, 30)):\n",
    "        self.grid_size = grid_size\n",
    "        self.grid = np.zeros(grid_size)\n",
    "\n",
    "    def create_map_ca(self):\n",
    "        width = self.grid.shape[0]\n",
    "        height = self.grid.shape[1]\n",
    "\n",
    "        for i in range(width):\n",
    "            for j in range(height):\n",
    "                if (i == 0 or i == width-1 or j == 0 or j == height -1):\n",
    "                    self.grid[i][j]=1\n",
    "                else:\n",
    "                    if (random.randint(0,100)>70):\n",
    "                        self.grid[i][j]=1\n",
    "                    else:\n",
    "                        self.grid[i][j]=0\n",
    "\n",
    "        for i in range(1, width - 1):\n",
    "            for j in range(1, height - 1):\n",
    "                neighbors = [self.grid[i-1][j], self.grid[i+1][j], self.grid[i][j-1], self.grid[i][j+1]]\n",
    "                if sum(neighbors) < 2 :\n",
    "                    self.grid[i][j] = 0\n",
    "                elif sum(neighbors) >3:\n",
    "                    self.grid[i][j]=1\n",
    "\n",
    "        return self.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e2cd57640>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_generation_ca = MapGenerationCA()\n",
    "ca_map = map_generation_ca.create_map_ca()\n",
    "map_image = render(ca_map, inline=True)\n",
    "# map_image = cv2.cvtColor(map_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(map_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Generation (Drunkard Walk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapGenerationDW():\n",
    "    def __init__(self, grid_size=(30, 30)):\n",
    "        self.grid_size = grid_size\n",
    "\n",
    "    def create_map_dw(self, fill_percentage=70):\n",
    "        width = self.grid_size[0]\n",
    "        height = self.grid_size[1]\n",
    "        self.grid = np.ones(self.grid_size)\n",
    "        counter = 0\n",
    "\n",
    "        x = random.randint(1,width-2)\n",
    "        y = random.randint(1,height-2)\n",
    "\n",
    "        while(counter<((width-2)*(height-2)*fill_percentage/100)):\n",
    "\n",
    "            move = random.randint(0,3)\n",
    "            if((x!=0) & (x!=width-1) & (y!=0) & (y!=height-1)):\n",
    "                #UP\n",
    "                if(move==0):\n",
    "                    if((x>0) & (x<width-1) & (y+1>0) & (y+1<height-1)):\n",
    "                        y=y+1\n",
    "                #RIGHT\n",
    "                elif(move==1):\n",
    "                    if((x+1>0) & (x+1<width-1) & (y>0) & (y<height-1)):\n",
    "                        x=x+1\n",
    "                #DOWN\n",
    "                elif(move==2):\n",
    "                    if((x>0) & (x<width-1) & (y-1>0) & (y-1<height-1)):\n",
    "                        y=y-1\n",
    "                #LEFT\n",
    "                else:\n",
    "                    if((x-1>0) & (x-1<width-1) & (y>0) & (y<height-1)):\n",
    "                        x=x-1\n",
    "                if(self.grid[x,y] == 1):\n",
    "                    counter+=1\n",
    "                self.grid[x,y] = 0\n",
    "\n",
    "        return self.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e2cd8d0a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_generation_dw = MapGenerationDW()\n",
    "dw_map = map_generation_dw.create_map_dw()\n",
    "map_image = render(dw_map, inline=True)\n",
    "# map_image = cv2.cvtColor(map_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(map_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Star Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AStarNode:        \n",
    "    def __init__(self, x, y, prev_node=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.prev_node = prev_node\n",
    "        self.gcost = 0\n",
    "        self.hcost = 0\n",
    "        self.fcost = 0\n",
    "\n",
    "    def calculate_fcost(self):\n",
    "        self.fcost = self.gcost + self.hcost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathFinder:\n",
    "    def __init__(self, grid, start_point, end_point):\n",
    "        self.grid = grid\n",
    "        self.start_point = start_point\n",
    "        self.end_point = end_point\n",
    "        self.path = []\n",
    "\n",
    "    def find_path(self):\n",
    "        start_node = AStarNode(self.start_point[0], self.start_point[1])\n",
    "        end_node = AStarNode(self.end_point[0], self.end_point[1])\n",
    "        current_node = None\n",
    "\n",
    "        width = self.grid.shape[0]\n",
    "        height = self.grid.shape[1]\n",
    "        directions = [[-1, 0], [1, 0], [0, 1], [0, -1]]\n",
    "\n",
    "        start_node.gcost = 0\n",
    "        start_node.hcost = self.calculate_distance_cost(start_node, end_node)\n",
    "        start_node.calculate_fcost()\n",
    "\n",
    "        open_list = [start_node]\n",
    "        closed_list = []\n",
    "\n",
    "        while len(open_list) > 0:\n",
    "            current_node = self.get_lowest_cost_node(open_list)\n",
    "\n",
    "            if current_node.x == end_node.x and current_node.y == end_node.y:\n",
    "                break\n",
    "\n",
    "            open_list.remove(current_node)\n",
    "            closed_list.append(current_node)\n",
    "\n",
    "            for i in range(len(directions)):\n",
    "                next_x = current_node.x + directions[i][0]\n",
    "                next_y= current_node.y + directions[i][1]\n",
    "                next_node = AStarNode(next_x, next_y, current_node)\n",
    "\n",
    "                already_visited = any(node.x == next_node.x and node.y == next_node.y for node in closed_list)\n",
    "                same_coor_index = next((i for i, node in enumerate(open_list) if node.x == next_node.x and node.y == next_node.y), -1)\n",
    "\n",
    "                if 0 <= next_x < width and 0 <= next_y < height and not already_visited and self.grid[next_x][next_y] != 1:\n",
    "                    gcost = current_node.gcost + self.calculate_distance_cost(current_node, next_node)\n",
    "                    next_node.gcost = gcost\n",
    "\n",
    "                    hcost = self.calculate_distance_cost(next_node, end_node)\n",
    "                    next_node.hcost = hcost\n",
    "\n",
    "                    next_node.calculate_fcost()\n",
    "\n",
    "                    if same_coor_index == -1 or (next_node.fcost < open_list[same_coor_index].fcost):\n",
    "                        open_list.append(next_node)\n",
    "\n",
    "#         print(\"Current Position: \")\n",
    "#         print(current_node.x, current_node.y)\n",
    "\n",
    "        traverse_node = current_node.prev_node\n",
    "        path_distance = 0\n",
    "\n",
    "        if traverse_node is not None:\n",
    "            while traverse_node.prev_node is not None:\n",
    "                path_distance += 1\n",
    "                self.grid[traverse_node.x][traverse_node.y] = 2\n",
    "                traverse_node = traverse_node.prev_node\n",
    "        else:\n",
    "            print(\"traverseNode is None\")\n",
    "\n",
    "#         print(\"Shortest Path Distance: \", path_distance)\n",
    "\n",
    "        # Append the coordinates of each node to the path list\n",
    "        while current_node is not None:\n",
    "            self.path.append((current_node.x, current_node.y))\n",
    "            current_node = current_node.prev_node\n",
    "\n",
    "        # Reverse the list so that it starts from the start point and ends at the end point\n",
    "        self.path = self.path[::-1]\n",
    "#         print(\"Path taken: \")\n",
    "#         print(self.path)\n",
    "\n",
    "        return self.path\n",
    "\n",
    "    # The CalculateDistanceCost method takes two AStarNode objects as input and returns the Manhattan distance between the two nodes.\n",
    "    def calculate_distance_cost(self, a, b):\n",
    "        x_distance = abs(a.x - b.x)\n",
    "        y_distance = abs(a.y - b.y)\n",
    "\n",
    "        # Manhattan distance formula\n",
    "        distance = x_distance + y_distance\n",
    "\n",
    "        return distance\n",
    "\n",
    "    # The GetLowestCostNode method takes a list of AStarNode objects and returns the node with the lowest fCost (total cost = gCost + hCost)\n",
    "    def get_lowest_cost_node(self, path_list):\n",
    "        lowest_cost_node = path_list[0]\n",
    "\n",
    "        for i in range(1, len(path_list)):\n",
    "            if path_list[i].fcost < lowest_cost_node.fcost:\n",
    "                lowest_cost_node = path_list[i]\n",
    "\n",
    "        return lowest_cost_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PacmanEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, grid, render_mode=None, ):\n",
    "        super(PacmanEnv, self).__init__()\n",
    "        self.grid = grid\n",
    "        \n",
    "        self.observation_space = spaces.MultiDiscrete([\n",
    "                self.grid.shape[0], # end_dist_x_left\n",
    "                self.grid.shape[0], # end_dist_x_right\n",
    "                self.grid.shape[1], # end_dist_y_top\n",
    "                self.grid.shape[1], # end_dist_y_bottom\n",
    "                4, #  prev_agent_action\n",
    "                self.grid.shape[0], # left_wall_dist\n",
    "                self.grid.shape[0], # right_wall_dist\n",
    "                self.grid.shape[1], # top_wall_dist\n",
    "                self.grid.shape[1], # bottom_wall_dist\n",
    "            ])\n",
    "\n",
    "        # We have 4 actions, corresponding to \"left\", \"up\", \"right\", \"down\"\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "    def get_interval_boundary_(self, walls, position):\n",
    "        lower_bound = 0\n",
    "        upper_bound = 0\n",
    "        for index, wall in enumerate(walls):\n",
    "            if wall < position:\n",
    "                lower_bound = wall\n",
    "                upper_bound = walls[index+1]\n",
    "\n",
    "        return lower_bound, upper_bound\n",
    "    \n",
    "    def reset(self, agent_position=None, end_position=None):\n",
    "        if agent_position is None and end_position is None:\n",
    "            while True:\n",
    "                start_point = [random.randint(0, 29), random.randint(0, 29)]\n",
    "                if self.grid[start_point[0]][start_point[1]] != 1:\n",
    "                    self.agent_position = start_point\n",
    "                    break\n",
    "\n",
    "            while True:\n",
    "                end_point = [random.randint(0, 29), random.randint(0, 29)]\n",
    "                if self.grid[end_point[0]][end_point[1]] != 1 and end_point != start_point:\n",
    "                    self.end_position = end_point\n",
    "                    break\n",
    "        else:\n",
    "            self.agent_position = agent_position\n",
    "            self.end_position = end_position\n",
    "            \n",
    "        self.score = 0\n",
    "        self.prev_reward = 0\n",
    "        self.action = 0\n",
    "        \n",
    "        self.done = False\n",
    "        \n",
    "        agent_x = max(0, self.agent_position[0])\n",
    "        agent_y = max(0, self.agent_position[1])\n",
    "        agent_end_dist_x = self.agent_position[0] - self.end_position[0] - 1\n",
    "        if agent_end_dist_x > 0:\n",
    "            end_distance_left = agent_end_dist_x\n",
    "            end_distance_right = 0\n",
    "        else:\n",
    "            end_distance_left = 0\n",
    "            end_distance_right = abs(agent_end_dist_x)\n",
    "        \n",
    "        agent_end_dist_y = self.agent_position[1] - self.end_position[1] - 1\n",
    "        if agent_end_dist_y > 0:\n",
    "            end_distance_top = agent_end_dist_y\n",
    "            end_distance_bottom = 0\n",
    "        else:\n",
    "            end_distance_top = 0\n",
    "            end_distance_bottom = abs(agent_end_dist_y)\n",
    "        \n",
    "        \n",
    "        self.prev_action = 0\n",
    "        horizontal_grid = self.grid[:, agent_y]\n",
    "        horizontal_wall_pos = np.where(horizontal_grid==1)[0]\n",
    "        horizontal_boundary = self.get_interval_boundary_(horizontal_wall_pos, agent_x)                                           \n",
    "        left_wall_dist = max(0, agent_x - horizontal_boundary[0] - 1)\n",
    "        right_wall_dist = max(0, horizontal_boundary[1] - agent_x - 1)\n",
    "        \n",
    "        vertical_grid = self.grid[agent_x, :]\n",
    "        vertical_wall_pos = np.where(vertical_grid==1)[0]\n",
    "        vertical_boundary = self.get_interval_boundary_(vertical_wall_pos, agent_y)\n",
    "        top_wall_dist = max(0, agent_y - vertical_boundary[0] - 1)\n",
    "        bottom_wall_dist = max(0, vertical_boundary[1] - agent_y - 1)\n",
    "\n",
    "        # create observation:\n",
    "        observation = [end_distance_left, end_distance_right, end_distance_top, end_distance_bottom, self.prev_action, \n",
    "                           left_wall_dist, right_wall_dist, top_wall_dist, bottom_wall_dist]\n",
    "        observation = np.array(observation)\n",
    "        return observation\n",
    "    \n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.agent_position[0] -= 1\n",
    "        elif action == 1:\n",
    "            self.agent_position[1] -= 1\n",
    "        elif action == 2:\n",
    "            self.agent_position[0] += 1\n",
    "        elif action == 3:\n",
    "            self.agent_position[1] += 1 \n",
    "        \n",
    "        # On collision on wall\n",
    "        if int(self.grid[self.agent_position[0], self.agent_position[1]]) == 1:\n",
    "            self.done = True\n",
    "            self.reward = -20\n",
    "        \n",
    "        # reward is based on the distance between pacman and pellet\n",
    "        grid_hypothenus = sqrt(self.grid.shape[0]**2 + self.grid.shape[1]**2)\n",
    "        pacman_pellet_distance = sqrt(abs(self.agent_position[0] - self.end_position[0])**2 + (self.agent_position[1] - self.end_position[1])**2)\n",
    "        \n",
    "        distance_ratio = pacman_pellet_distance/grid_hypothenus\n",
    "        if distance_ratio > 0.8:\n",
    "            self.total_reward = 1\n",
    "        elif distance_ratio > 0.6:\n",
    "            self.total_reward = 3\n",
    "        if distance_ratio > 0.4:\n",
    "            self.total_reward = 7\n",
    "        if distance_ratio > 0.2:\n",
    "            self.total_reward = 10\n",
    "        else:\n",
    "            self.total_reward = 15\n",
    "        \n",
    "        self.reward = self.total_reward - self.prev_reward\n",
    "        self.prev_reward = self.total_reward\n",
    "            \n",
    "        if self.agent_position == self.end_position:\n",
    "            self.reward = 20\n",
    "            self.done = True\n",
    "\n",
    "        agent_x = max(0, self.agent_position[0])\n",
    "        agent_y = max(0, self.agent_position[1])\n",
    "        agent_end_dist_x = self.agent_position[0] - self.end_position[0] - 1\n",
    "        if agent_end_dist_x > 0:\n",
    "            end_distance_left = agent_end_dist_x\n",
    "            end_distance_right = 0\n",
    "        else:\n",
    "            end_distance_left = 0\n",
    "            end_distance_right = abs(agent_end_dist_x)\n",
    "        \n",
    "        agent_end_dist_y = self.agent_position[1] - self.end_position[1] - 1\n",
    "        if agent_end_dist_y > 0:\n",
    "            end_distance_top = agent_end_dist_y\n",
    "            end_distance_bottom = 0\n",
    "        else:\n",
    "            end_distance_top = 0\n",
    "            end_distance_bottom = abs(agent_end_dist_y)\n",
    "        self.prev_action = action\n",
    "        \n",
    "        horizontal_grid = self.grid[:, agent_y]\n",
    "        horizontal_wall_pos = np.where(horizontal_grid==1)[0]\n",
    "        horizontal_boundary = self.get_interval_boundary_(horizontal_wall_pos, agent_x)                                           \n",
    "        left_wall_dist = max(0, agent_x - horizontal_boundary[0] - 1)\n",
    "        right_wall_dist = max(0, horizontal_boundary[1] - agent_x - 1)\n",
    "        \n",
    "        vertical_grid = self.grid[agent_x, :]\n",
    "        vertical_wall_pos = np.where(vertical_grid==1)[0]\n",
    "        vertical_boundary = self.get_interval_boundary_(vertical_wall_pos, agent_y)\n",
    "        top_wall_dist = max(0, agent_y - vertical_boundary[0] - 1)\n",
    "        bottom_wall_dist = max(0, vertical_boundary[1] - agent_y - 1)\n",
    "\n",
    "        # create observation:\n",
    "        observation = [end_distance_left, end_distance_right, end_distance_top, end_distance_bottom, self.prev_action, \n",
    "                           left_wall_dist, right_wall_dist, top_wall_dist, bottom_wall_dist]\n",
    "        observation = np.array(observation)\n",
    "        info = {}\n",
    "        \n",
    "        return observation, self.reward, self.done, info\n",
    "    \n",
    "    def render(self, step_count):\n",
    "        game_visual = np.zeros((self.grid.shape[0], self.grid.shape[1], 3), np.uint8)\n",
    "        wall_pos = np.where(self.grid==1)\n",
    "        for index, _ in enumerate(wall_pos[0]):\n",
    "            game_visual[wall_pos[0][index], wall_pos[1][index]] = (3, 78, 252)\n",
    "        \n",
    "        if self.agent_position == self.end_position:\n",
    "            game_visual[self.end_position[0], self.end_position[1]] = (0, 255, 0) \n",
    "            \n",
    "        else:\n",
    "            game_visual[self.agent_position[0], self.agent_position[1]] = (255, 255, 255) \n",
    "            game_visual[self.end_position[0], self.end_position[1]] = (247, 235, 10) \n",
    "            \n",
    "#         game_visual = game_visual.repeat(10, axis=0).repeat(2, axis=1)\n",
    "        game_visual = cv2.cvtColor(game_visual, cv2.COLOR_BGR2RGB)\n",
    "        cv2.namedWindow(\"Pacman Simplified\", cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(\"Pacman Simplified\", 500, 500)\n",
    "        cv2.imshow('Pacman Simplified', game_visual)\n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "        print('done')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.A Map (A Star vs Reinforcement Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Point: \n",
      "(8, 24)\n",
      "End Point: \n",
      "(20, 26)\n"
     ]
    }
   ],
   "source": [
    "map_generation_ca = MapGenerationCA()\n",
    "ca_map = map_generation_ca.create_map_ca()\n",
    "\n",
    "while True:\n",
    "    start_point = (random.randint(0, 29), random.randint(0, 29))\n",
    "    if ca_map[start_point[0]][start_point[1]] != 1:\n",
    "        break\n",
    "\n",
    "while True:\n",
    "    end_point = (random.randint(0, 29), random.randint(0, 29))\n",
    "    if ca_map[end_point[0]][end_point[1]] != 1 and end_point != start_point:\n",
    "        break\n",
    "        \n",
    "print(\"Start Point: \")\n",
    "print(start_point)\n",
    "print(\"End Point: \")\n",
    "print(end_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps taken: 15\n"
     ]
    }
   ],
   "source": [
    "if ca_map[start_point[0]][start_point[1]] != 1 and ca_map[end_point[0]][end_point[1]] != 1:\n",
    "    # Call the A* function to find the path from the start to the end point\n",
    "    path_finder = PathFinder(ca_map, start_point, end_point)\n",
    "    path = path_finder.find_path()\n",
    "    \n",
    "    for agent_point in path:\n",
    "        render(ca_map, agent_point, end_point)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    time.sleep(2)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f'Steps taken: {len(path)}')\n",
    "else:\n",
    "    print(\"Start point or end point is on a wall. Please choose new coordinates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps taken: 14\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model_new = PPO.load('rl_model.zip')\n",
    "env = PacmanEnv(ca_map)\n",
    "observation = env.reset(agent_position=[start_point[0], start_point[1]], end_position=[end_point[0], end_point[1]])\n",
    "done = False\n",
    "step_count = 0\n",
    "env.render(step_count)\n",
    "while not done:\n",
    "    action = model_new.predict(observation)[0]\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    env.render(step_count)\n",
    "    time.sleep(0.1)\n",
    "    step_count+=1\n",
    "print(f'Steps taken: {step_count}')\n",
    "time.sleep(2)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drunken Walk Map (A Star vs Reinforcement Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Point: \n",
      "(24, 7)\n",
      "End Point: \n",
      "(1, 14)\n"
     ]
    }
   ],
   "source": [
    "map_generation_dw = MapGenerationDW()\n",
    "dw_map = map_generation_dw.create_map_dw()\n",
    "\n",
    "while True:\n",
    "    start_point = (random.randint(0, 29), random.randint(0, 29))\n",
    "    if dw_map[start_point[0]][start_point[1]] != 1:\n",
    "        break\n",
    "\n",
    "while True:\n",
    "    end_point = (random.randint(0, 29), random.randint(0, 29))\n",
    "    if dw_map[end_point[0]][end_point[1]] != 1 and end_point != start_point:\n",
    "        break\n",
    "        \n",
    "print(\"Start Point: \")\n",
    "print(start_point)\n",
    "print(\"End Point: \")\n",
    "print(end_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps taken: 37\n"
     ]
    }
   ],
   "source": [
    "if dw_map[start_point[0]][start_point[1]] != 1 and dw_map[end_point[0]][end_point[1]] != 1:\n",
    "    # Call the A* function to find the path from the start to the end point\n",
    "    path_finder = PathFinder(dw_map, start_point, end_point)\n",
    "    path = path_finder.find_path()\n",
    "    \n",
    "    for agent_point in path:\n",
    "        render(dw_map, agent_point, end_point)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    time.sleep(2)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f'Steps taken: {len(path)}')\n",
    "else:\n",
    "    print(\"Start point or end point is on a wall. Please choose new coordinates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps taken: 150\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model_new = PPO.load('rl_model.zip')\n",
    "env = PacmanEnv(dw_map)\n",
    "observation = env.reset(agent_position=[start_point[0], start_point[1]], end_position=[end_point[0], end_point[1]])\n",
    "done = False\n",
    "step_count = 0\n",
    "env.render(step_count)\n",
    "while not done:\n",
    "    action = model_new.predict(observation)[0]\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    env.render(step_count)\n",
    "    time.sleep(0.1)\n",
    "    step_count+=1\n",
    "print(f'Steps taken: {step_count}')\n",
    "time.sleep(2)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of the Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Finder Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"PathFinder\" that uses the A* algorithm to find the shortest path between a start point and an end point on a given map.\n",
    "\n",
    "The class has 3 instance variables:\n",
    "\n",
    "- \"map\": a 2D array representing the map, where 0 represents an empty cell and 1 represents an obstacle\n",
    "- \"startPoint\": a tuple containing the x, y coordinates of the starting point on the map\n",
    "- \"endPoint\": a tuple containing the x, y coordinates of the ending point on the map\n",
    "- \"path\": a list that will store the coordinates of each node in the path from start to end point\n",
    "- The class has three methods:\n",
    "\n",
    "- The init method initializes the instance variables when a new object of the class is created.\n",
    "- The FindPath method is where the A* algorithm is implemented. It uses the Manhattan distance formula to calculate the distance cost between two nodes and uses that cost to determine the best path from the start point to the end point.\n",
    "- The CalculateDistanceCost method takes two AStarNode objects as input and returns the Manhattan distance between the two nodes.\n",
    "- The GetLowestCostNode method takes a list of AStarNode objects and returns the node with the lowest fCost (total cost = gCost + hCost)\n",
    "\n",
    "The A* algorithm works by:\n",
    "\n",
    "1. Creating a start and end node from the start and end points passed to the class.\n",
    "2. Initializing the gCost (movement cost from the start node to the current node) and hCost (estimated movement cost from the current node to the end node) of the start node.\n",
    "3. Creating an open list and a closed list and adding the start node to the open list.\n",
    "4. While the open list is not empty:\n",
    "5. Getting the node with the lowest fCost (total cost) from the open list, this node will be the current node.\n",
    "6. If the current node is the end node, the algorithm has found the shortest path and the method returns the path.\n",
    "7. Removing the current node from the open list and adding it to the closed list.\n",
    "8. For each possible direction from the current node, checking if the next node is within the boundaries of the map, has not been visited before and is not an obstacle.\n",
    "9. If the next node is a valid node, calculating its gCost and hCost and adding it to the open list.\n",
    "10. If the next node is already in the open list and has a lower fCost than the current one, update the fCost and the parent of the node.\n",
    "11. When the open list is empty, the algorithm has not found a path.\n",
    "12. The path variable is filled with the nodes traversed in reverse order and returned.\n",
    "13. The path is plotted on the map using matplotlib."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
